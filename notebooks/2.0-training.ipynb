{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## SVD\n",
    "\n",
    "![Fig 1. Movie Genres](imgs/sparse_matrix.png)\n",
    "\n",
    "As data exploration has shown, the matrices of user reviews and movie genres are too sparse. Storing those matrices without any amendments will require a lot of RAM. However, SVD will implicitly help us by making the matrices more dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports are here\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also filter the warnings because who needs them, right?\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "\n",
    "    '''\n",
    "\n",
    "    The MatrixFactorization class is designed for matrix factorization-based collaborative\n",
    "    filtering using PyTorch. It learns embeddings for users and items in a matrix,\n",
    "    enabling the prediction of user-item interactions.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "\n",
    "        # User embeddings (users to their features)\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "\n",
    "        # Movie embeddings (movies to their features)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        users, movies = data[:, 0], data[:, 1]\n",
    "        return (self.user_factors(users) * self.item_factors(movies)).sum(1)\n",
    "    \n",
    "    def predict(self, user, movie):\n",
    "        return self.forward(user, movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "\n",
    "class Loader(Dataset):\n",
    "\n",
    "    '''\n",
    "\n",
    "    The Loader class is a PyTorch Dataset used for handling rating data.\n",
    "    It transforms the input ratings dataset into a format suitable for training\n",
    "    machine learning models.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ratings_df):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Obtaining all unique user and movie ids\n",
    "        users = ratings_df[\"user_id\"].unique()\n",
    "        movies = ratings_df[\"movie_id\"].unique()\n",
    "        \n",
    "        # We need to create mappings from unique vals to indices\n",
    "        self.userid2idx = {o: i for i, o in enumerate(users)}\n",
    "        self.movieid2idx = {o: i for i, o in enumerate(movies)}\n",
    "        \n",
    "        # Doing the opposite thing\n",
    "        self.idx2userid = {i: o for o, i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i: o for o, i in self.movieid2idx.items()}\n",
    "        \n",
    "        # We also need to replace initial ids with indices\n",
    "        self.ratings[\"movie_id\"] = ratings_df[\"movie_id\"].apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings[\"user_id\"]= ratings_df[\"user_id\"].apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y)\n",
    "\n",
    "    # Return item by its index\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    # Return len of ratings\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alrighty, training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "# Dataset root folder\n",
    "dataset_root_path = \"../data/interim/ml-100k\"\n",
    "\n",
    "# We use this df to obtain info about movies\n",
    "u_item_df = pd.read_csv(f\"{dataset_root_path}/u.item\",\n",
    "                        delimiter=\"|\",\n",
    "                     #    index_col=0,\n",
    "                        names=[\"movie_id\", \"movie_title\", \"release_date\",\n",
    "                               \"video_release_date\", \"IMDb_URL\",\n",
    "                               \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Childrens\",\n",
    "                               \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n",
    "                               \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\",\n",
    "                               \"War\", \"Western\"],\n",
    "                        encoding=\"cp1252\")\n",
    "\n",
    "# We need this df to know how each user rated the movies they watched\n",
    "u_data_df = pd.read_csv(f\"{dataset_root_path}/u.data\", delimiter=\"\\t\", names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mat%27+i+syn+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?B%2E+Monkey+(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Sliding+Doors+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?You%20So%20Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Schrei%20aus%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                                movie_title release_date  \\\n",
       "1677      1678                          Mat' i syn (1997)  06-Feb-1998   \n",
       "1678      1679                           B. Monkey (1998)  06-Feb-1998   \n",
       "1679      1680                       Sliding Doors (1998)  01-Jan-1998   \n",
       "1680      1681                        You So Crazy (1994)  01-Jan-1994   \n",
       "1681      1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996   \n",
       "\n",
       "      video_release_date                                           IMDb_URL  \\\n",
       "1677                 NaN  http://us.imdb.com/M/title-exact?Mat%27+i+syn+...   \n",
       "1678                 NaN  http://us.imdb.com/M/title-exact?B%2E+Monkey+(...   \n",
       "1679                 NaN      http://us.imdb.com/Title?Sliding+Doors+(1998)   \n",
       "1680                 NaN  http://us.imdb.com/M/title-exact?You%20So%20Cr...   \n",
       "1681                 NaN  http://us.imdb.com/M/title-exact?Schrei%20aus%...   \n",
       "\n",
       "      unknown  Action  Adventure  Animation  Childrens  ...  Fantasy  \\\n",
       "1677        0       0          0          0          0  ...        0   \n",
       "1678        0       0          0          0          0  ...        0   \n",
       "1679        0       0          0          0          0  ...        0   \n",
       "1680        0       0          0          0          0  ...        0   \n",
       "1681        0       0          0          0          0  ...        0   \n",
       "\n",
       "      Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
       "1677          0       0        0        0        0       0         0    0   \n",
       "1678          0       0        0        0        1       0         1    0   \n",
       "1679          0       0        0        0        1       0         0    0   \n",
       "1680          0       0        0        0        0       0         0    0   \n",
       "1681          0       0        0        0        0       0         0    0   \n",
       "\n",
       "      Western  \n",
       "1677        0  \n",
       "1678        0  \n",
       "1679        0  \n",
       "1680        0  \n",
       "1681        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_item_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to set index to \"movie_id\" because otherwise our ids will start with 0\n",
    "# and won't correspond to true ids in the df\n",
    "movie_titles = u_item_df.set_index(\"movie_id\")['movie_title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)'),\n",
       " (2, 'GoldenEye (1995)'),\n",
       " (3, 'Four Rooms (1995)'),\n",
       " (4, 'Get Shorty (1995)'),\n",
       " (5, 'Copycat (1995)'),\n",
       " (6, 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)'),\n",
       " (7, 'Twelve Monkeys (1995)'),\n",
       " (8, 'Babe (1995)'),\n",
       " (9, 'Dead Man Walking (1995)'),\n",
       " (10, 'Richard III (1995)')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movie_titles.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    '''\n",
    "    \n",
    "    TrainingConfig class contains training parameters like number of epochs\n",
    "    or device that is to be used for training\n",
    "\n",
    "    '''\n",
    "\n",
    "    num_epochs = 128\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = torch.device(\"mps\")\n",
    "    n_factors = 8\n",
    "    batch_size = 128\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(u_data_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_set = Loader(train_data)\n",
    "test_set = Loader(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_set, config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to count the number of unique users and movies\n",
    "num_unique_movies = len(u_item_df['movie_id'].unique())\n",
    "num_unique_users = len(u_data_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(943, 8)\n",
      "  (item_factors): Embedding(1682, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0097, 0.0357, 0.0344,  ..., 0.0273, 0.0399, 0.0004],\n",
      "        [0.0177, 0.0316, 0.0452,  ..., 0.0409, 0.0219, 0.0284],\n",
      "        [0.0137, 0.0331, 0.0010,  ..., 0.0212, 0.0199, 0.0410],\n",
      "        ...,\n",
      "        [0.0188, 0.0443, 0.0257,  ..., 0.0497, 0.0361, 0.0229],\n",
      "        [0.0424, 0.0274, 0.0378,  ..., 0.0461, 0.0134, 0.0172],\n",
      "        [0.0307, 0.0500, 0.0127,  ..., 0.0254, 0.0348, 0.0248]])\n",
      "item_factors.weight tensor([[0.0144, 0.0250, 0.0271,  ..., 0.0485, 0.0326, 0.0013],\n",
      "        [0.0018, 0.0428, 0.0124,  ..., 0.0251, 0.0243, 0.0365],\n",
      "        [0.0015, 0.0025, 0.0471,  ..., 0.0342, 0.0207, 0.0091],\n",
      "        ...,\n",
      "        [0.0325, 0.0008, 0.0116,  ..., 0.0130, 0.0260, 0.0454],\n",
      "        [0.0219, 0.0225, 0.0450,  ..., 0.0329, 0.0373, 0.0384],\n",
      "        [0.0259, 0.0096, 0.0337,  ..., 0.0075, 0.0499, 0.0078]])\n"
     ]
    }
   ],
   "source": [
    "model = MatrixFactorization(num_unique_users, num_unique_movies, n_factors=config.n_factors)\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "model = model.to(config.device)\n",
    "\n",
    "# We will be using MSE\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# And Adam optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [00:00<00:45,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 11.584645626831055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 11/128 [00:04<00:43,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #10 Loss: 0.8774093044281006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 21/128 [00:07<00:37,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #20 Loss: 0.8574844573974609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 31/128 [00:11<00:32,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #30 Loss: 0.8535347853660583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 41/128 [00:14<00:30,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #40 Loss: 0.846245800113678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 51/128 [00:17<00:25,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #50 Loss: 0.8121151856422424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 61/128 [00:21<00:23,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #60 Loss: 0.7336387606620789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 71/128 [00:24<00:19,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #70 Loss: 0.6601696525096893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 81/128 [00:28<00:15,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #80 Loss: 0.6141407647132874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 91/128 [00:31<00:12,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #90 Loss: 0.5882021836280823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 101/128 [00:35<00:09,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #100 Loss: 0.5717136323928833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 111/128 [00:38<00:05,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #110 Loss: 0.5602877286911011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 121/128 [00:42<00:02,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #120 Loss: 0.5515826260089874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:44<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training!\n",
    "\n",
    "for it in tqdm(range(config.num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(config.device)\n",
    "        y = y.to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if it % 10 == 0:\n",
    "        print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[ 0.8476,  0.8253,  0.6640,  ...,  0.8427,  0.8989,  0.7390],\n",
      "        [ 0.2304,  0.6788,  0.4748,  ...,  0.7793,  0.6262,  1.0967],\n",
      "        [-0.0579,  0.4145,  0.1376,  ...,  0.7945,  1.0740,  1.3434],\n",
      "        ...,\n",
      "        [ 1.0189,  1.0269,  0.9430,  ...,  0.9768,  1.0965,  0.3477],\n",
      "        [ 1.2472,  0.8574,  0.9157,  ...,  0.3859, -0.4035,  1.2180],\n",
      "        [ 1.4851,  0.6886,  0.8468,  ...,  0.9567,  0.2881,  0.1356]])\n",
      "item_factors.weight tensor([[ 1.7173e+00,  6.6317e-01,  1.9755e-02,  ...,  2.8416e-01,\n",
      "          4.0860e-01,  7.8730e-01],\n",
      "        [ 1.3372e-01,  7.7562e-01,  8.1220e-01,  ...,  4.7229e-01,\n",
      "          1.3030e+00,  4.9817e-01],\n",
      "        [-1.5361e-01,  6.0543e-01,  1.0321e+00,  ...,  5.8205e-01,\n",
      "          1.6133e+00, -1.6326e-01],\n",
      "        ...,\n",
      "        [ 3.2501e-02,  7.8330e-04,  1.1577e-02,  ...,  1.3008e-02,\n",
      "          2.5963e-02,  4.5415e-02],\n",
      "        [ 2.1864e-02,  2.2469e-02,  4.4998e-02,  ...,  3.2919e-02,\n",
      "          3.7335e-02,  3.8382e-02],\n",
      "        [ 2.5885e-02,  9.6271e-03,  3.3686e-02,  ...,  7.4793e-03,\n",
      "          4.9940e-02,  7.7529e-03]])\n"
     ]
    }
   ],
   "source": [
    "c = 0   # counter\n",
    "uw = 0  # user embeddings\n",
    "iw = 0  # movie embeddings\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c += 1\n",
    "        else:\n",
    "          iw = param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()\n",
    "\n",
    "print(len(trained_movie_embeddings)) # Here are unique movie factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use KMeans to fit the clusters using the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Crow: City of Angels, The (1996)\n",
      "\t Bio-Dome (1996)\n",
      "\t Barb Wire (1996)\n",
      "\t Lawnmower Man 2: Beyond Cyberspace (1996)\n",
      "\t Children of the Corn: The Gathering (1996)\n",
      "\t Big Bully (1996)\n",
      "\t Mr. Magoo (1997)\n",
      "\t Mighty Morphin Power Rangers: The Movie (1995)\n",
      "\t House Party 3 (1994)\n",
      "\t Meet Wally Sparks (1997)\n",
      "Cluster #1\n",
      "\t Toy Story (1995)\n",
      "\t Raiders of the Lost Ark (1981)\n",
      "\t Godfather, The (1972)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Jerry Maguire (1996)\n",
      "\t Empire Strikes Back, The (1980)\n",
      "\t Back to the Future (1985)\n",
      "\t Titanic (1997)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Fugitive, The (1993)\n",
      "Cluster #2\n",
      "\t Contact (1997)\n",
      "\t Rock, The (1996)\n",
      "\t Star Trek: First Contact (1996)\n",
      "\t Saint, The (1997)\n",
      "\t Conspiracy Theory (1997)\n",
      "\t Mr. Holland's Opus (1995)\n",
      "\t Twister (1996)\n",
      "\t Truth About Cats & Dogs, The (1996)\n",
      "\t Ransom (1996)\n",
      "\t Game, The (1997)\n",
      "Cluster #3\n",
      "\t Liar Liar (1997)\n",
      "\t Air Force One (1997)\n",
      "\t Independence Day (ID4) (1996)\n",
      "\t Dante's Peak (1997)\n",
      "\t Top Gun (1986)\n",
      "\t Volcano (1997)\n",
      "\t Murder at 1600 (1997)\n",
      "\t American President, The (1995)\n",
      "\t Dragonheart (1996)\n",
      "\t Executive Decision (1996)\n",
      "Cluster #4\n",
      "\t Fargo (1996)\n",
      "\t English Patient, The (1996)\n",
      "\t Full Monty, The (1997)\n",
      "\t Dead Man Walking (1995)\n",
      "\t Leaving Las Vegas (1995)\n",
      "\t Four Weddings and a Funeral (1994)\n",
      "\t Graduate, The (1967)\n",
      "\t It's a Wonderful Life (1946)\n",
      "\t Butch Cassidy and the Sundance Kid (1969)\n",
      "\t M*A*S*H (1970)\n"
     ]
    }
   ],
   "source": [
    "# We can notice that movies of the same cluster are more likely to have\n",
    "# similar genre names\n",
    "\n",
    "num_clusters_to_check = 5\n",
    "\n",
    "for cluster in range(num_clusters_to_check):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    movs = []\n",
    "    for movie_idx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        try:\n",
    "            movie_id = train_set.idx2movieid[movie_idx]\n",
    "            rat_count = u_data_df.loc[u_data_df['movie_id'] == movie_id].count()[0]\n",
    "            movs.append((movie_titles[movie_id], rat_count))\n",
    "        except:\n",
    "            pass\n",
    "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", mov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model!\n",
    "\n",
    "model_path = f'../models/supermodel.pth'\n",
    "torch.save(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
